---
# ansible-playbook "$MYRIA_ANSIBLE_DIR/site.yml" --extra-vars "$ANSIBLE_VARS" --private-key "$PRIVATE_KEY_FILE"
- name: Create AWS resources
  hosts: localhost
  connection: local
  gather_facts: False
  vars:
    wait_timeout: 3600
    spot_wait_timeout: 3600
  tasks:

  - name: Create EC2 keypair if absent
    ec2_key:
      name: "{{KEY_PAIR}}"
      region: "{{REGION}}"
    register: key_pair
  - name: Check for existing private key file
    stat: path="{{PRIVATE_KEY_FILE}}"
    register: private_key_file
  - name: Fail if new keypair was created but private key file already exists
    fail: msg="Keypair '{{KEY_PAIR}}' was successfully created but private key file {{PRIVATE_KEY_FILE}} already exists! Please delete or rename it, delete the keypair '{{KEY_PAIR}}' from the {{REGION}} region, and rerun the script."
    when: (key_pair.changed) and (private_key_file.stat.exists)
  - name: Fail if keypair already exists but private key file is missing
    fail: msg="Keypair '{{KEY_PAIR}}' exists but private key file {{PRIVATE_KEY_FILE}} is missing! Please copy the private key file for the keypair '{{KEY_PAIR}}' to {{PRIVATE_KEY_FILE}} or delete the keypair '{{KEY_PAIR}}' from the {{REGION}} region, and rerun the script."
    when: (not (key_pair.changed)) and (not (private_key_file.stat.exists))
  - name: Save private key to file
    copy: content="{{ key_pair.key.private_key }}" dest="{{PRIVATE_KEY_FILE}}" mode=0600
    when: (key_pair.changed)

  - name: Create security group for this cluster
    ec2_group:
      name: "{{CLUSTER_NAME}}"
      description: "Myria security group"
      region: "{{REGION}}"
      profile: "{{PROFILE | default(omit)}}"
      vpc_id: "{{VPC_ID | default(omit)}}"
      rules:
      - proto: all
        from_port: 0
        to_port: 65535
        # self-reference by name so we can define the group in one pass (which is necessary for the duplicate detection in the next task to work)
        # FIXME: according to AWS docs, reference by name won't work in non-default VPC (must use group_id)
        group_name: "{{CLUSTER_NAME}}"
      - proto: tcp
        from_port: 22
        to_port: 22
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: 80
        to_port: 80
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: 443
        to_port: 443
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: "{{myria_rest_port}}"
        to_port: "{{myria_rest_port}}"
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: "{{myria_web_port}}"
        to_port: "{{myria_web_port}}"
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: "{{ganglia_web_port}}"
        to_port: "{{ganglia_web_port}}"
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: 8088
        to_port: 8088
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: 8042
        to_port: 8042
        cidr_ip: 0.0.0.0/0
      rules_egress:
      - proto: all
        cidr_ip: 0.0.0.0/0
    register: ec2_group

  - name: Fail if security group already exists with the same name as this cluster
    fail: msg="Security group '{{CLUSTER_NAME}}' already exists. Please terminate all instances in this security group and then delete the security group."
    when: not (ec2_group.changed)

  - name: Tag security group to designate as Myria cluster
    ec2_tag:
      profile: "{{PROFILE | default(omit)}}"
      region: "{{REGION}}"
      resource: "{{ec2_group.group_id}}"
      state: present
      tags:
        app: "myria"

  - name: Launch instances
    ec2:
      profile: "{{PROFILE | default(omit)}}"
      keypair: "{{KEY_PAIR}}"
      group_id: "{{ec2_group.group_id}}"
      instance_type: "{{INSTANCE_TYPE}}"
      image: "{{AMI_ID}}"
      vpc_subnet_id: "{{SUBNET_ID | default(omit)}}"
      instance_profile_name: "{{ROLE | default(omit)}}"
      count: "{{CLUSTER_SIZE}}"
      spot_price: "{{SPOT_PRICE | default(omit)}}"
      spot_wait_timeout: "{{ spot_wait_timeout }}"
      # add for ansible 2.1
      #spot_launch_group: "{{CLUSTER_NAME | default(omit)}}"
      wait: yes
      wait_timeout: "{{wait_timeout}}"
      region: "{{REGION}}"
      zone: "{{ZONE | default(omit)}}"

      instance_tags:
        cluster-name: "{{CLUSTER_NAME | default(omit)}}"
        spot-price: "{{SPOT_PRICE | default(omit)}}"
      volumes:
      - device_name: "{{ data_vol_device_name }}"
        volume_size: "{{ DATA_VOLUME_SIZE_GB }}"
        volume_type: "{{ data_vol_storage_type }}"
        delete_on_termination: true
    register: ec2

  - name: Tag coordinator
    ec2_tag:
      profile: "{{PROFILE | default(omit)}}"
      region: "{{REGION}}"
      resource: "{{ item.id }}"
      state: present
      tags:
        Name: "{{CLUSTER_NAME}}-{{USER}}-coordinator"
        cluster-role: coordinator
    with_items: ec2.instances[:1]

  - name: Tag workers
    ec2_tag:
      profile: "{{PROFILE | default(omit)}}"
      region: "{{REGION}}"
      resource: "{{ item.1.id }}"
      state: present
      tags:
        Name: "{{CLUSTER_NAME}}-{{USER}}-worker-{{item.0+1}}"
        cluster-role: worker
    with_indexed_items: "{{ ec2.instances[1:] | sort(attribute='private_dns_name') }}"

  - name: Add new instances to host group
    add_host: hostname={{item.public_ip}} groupname=nodes
    with_items: ec2.instances

  - name: Add first instance to coordinators group
    add_host: hostname={{item.public_ip}} groupname=coordinators
    with_items: ec2.instances[:1]

  - name: Add first instance to rmnode group
    add_host: hostname={{item.public_ip}} groupname=rmnode
    with_items: ec2.instances[:1]

  - name: Add first instance to rmnode_private group
    add_host: hostname={{item.private_ip}} groupname=rmnode_private
    with_items: ec2.instances[:1]

  - name: Add first instance to ganglia_master group
    add_host: hostname={{item.private_ip}} groupname=ganglia_master
    with_items: ec2.instances[:1]

  - name: Add remaining instances to workers group
    add_host: hostname={{item.public_ip}} groupname=workers
    with_items: ec2.instances[1:]

  - name: Add all instances to nmnodes group
    add_host: hostname={{item.public_ip}} groupname=nmnodes
    with_items: ec2.instances

  - name: Add all instances to nmnodes_private group
    add_host: hostname={{item.private_ip}} groupname=nmnodes_private
    with_items: ec2.instances

  - name: Add coordinator public DNS to coordinator_name group
    add_host: hostname={{item.dns_name}} groupname=coordinator_name
    with_items: ec2.instances[:1]

  - name: Add workers public DNS to worker_names group
    add_host: hostname={{item.dns_name}} groupname=worker_names
    with_items: ec2.instances[1:]

  - name: Add coordinator private DNS to coordinator_private_name group
    add_host: hostname={{item.private_dns_name}} groupname=coordinator_private_name
    with_items: ec2.instances[:1]

  - name: Add workers private DNS to worker_private_names group
    add_host: hostname={{item.private_dns_name}} groupname=worker_private_names
    with_items: ec2.instances[1:]

  - name: Wait for SSH to come up on all nodes
    wait_for: host={{ item.public_ip }} port=22 delay=0 timeout=300 state=started
    sudo: false
    async: 300
    poll: 30
    with_items: ec2.instances

- name: Configure common functionality on all nodes
  hosts: nodes
  remote_user: ubuntu
  sudo: yes
  gather_facts: true
  roles:
    - basenode
    - yarn-common
    - postgres
    - ganglia-monitor

- name: Configure YARN RM
  hosts: rmnode
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - yarn-master

- name: Configure YARN NM
  hosts: nmnodes
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - yarn-slave

- name: Configure Ganglia UI on coordinator
  hosts: coordinators
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - ganglia-metad
    - ganglia-web

- name: Configure and launch MyriaX on coordinator
  hosts: coordinators
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - myria-python
    - myria

- name: Install and launch myria-web on coordinator
  hosts: coordinators
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - gae
    - myria-web

- name: display connection information for coordinator
  hosts: localhost
  connection: local
  tasks:
    - shell: "echo http://{{ hostvars[groups['coordinator_name'][0]]['inventory_hostname'] }}:{{ myria_web_port }} > /tmp/{{CLUSTER_NAME}}-myria-web.url"
    - shell: "echo http://{{ hostvars[groups['coordinator_name'][0]]['inventory_hostname'] }}:{{ myria_rest_port }} > /tmp/{{CLUSTER_NAME}}-myria-rest.url"
    - shell: "echo http://{{ hostvars[groups['coordinator_name'][0]]['inventory_hostname'] }}:{{ ganglia_web_port }} > /tmp/{{CLUSTER_NAME}}-ganglia-web.url"
    - shell: "echo {{ myria_user }}@{{ hostvars[groups['coordinator_name'][0]]['inventory_hostname'] }} > /tmp/{{CLUSTER_NAME}}-myria-ssh-user-host.txt"
