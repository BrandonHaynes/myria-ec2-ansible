---
##ansible-playbook myria.yml "-e KEY_NAME=parmita-keypair"
- name: Create AWS resources
  hosts: localhost
  gather_facts: False
  vars:
    key_name: "{{ KEY_NAME }}"
    instance_type: t2.large
    instance_count: 3
    security_group: default
    image: ami-5189a661
    region: us-west-2
    wait_timeout: 600
  tasks:
  - name: Create security group  #so we can ssh into the instance from our laptop
    ec2_group:
      name: myriasec
      description: "A Security group"
      region: "{{region}}"
      rules:
      - proto: tcp
        type: ssh
        from_port: 22
        to_port: 22
        cidr_ip: 0.0.0.0/0
      - proto: tcp 
        type: myria
        from_port: 8753
        to_port: 8753
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        type: http
        from_port: 80
        to_port: 80
        cidr_ip: 0.0.0.0/0
      - proto: udp
        type: ganglia
        from_port: 8649
        to_port: 8649
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        type: https
        from_port: 443
        to_port: 443
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        type: postgres
        from_port: 5432
        to_port: 5432
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        type: namenode
        from_port: 8020
        to_port: 8020
      - proto: tcp
        type: datanode
        from_port: 50010
        to_port: 50075
      - proto: tcp
        type: zookeeper
        from_port: 2181
        to_port: 2181
      - proto: tcp
        type: resourcemanager
        from_port: 8032
        to_port: 8032
      - proto: tcp
        type: resourcemanager-scheduler
        from_port: 8030
        to_port: 8030
      - proto: tcp
        type: resourcemanager-tracker
        from_port: 8025
        to_port: 8025
      - proto: tcp
        type: resourcemanager-admin
        from_port: 8033
        to_port: 8033
      - proto: tcp
        type: resourcemanager-ui
        from_port: 8088
        to_port: 8088
      - proto: tcp
        type: nodemanager-ui
        from_port: 8042
        to_port: 8042
      rules_egress:
      - proto: all
        type: all
        cidr_ip: 0.0.0.0/0
    register: basic_firewall

  - name: Launch instance
    ec2:
      keypair: "{{key_name}}"
      group_id: "{{basic_firewall.group_id}}"
      instance_type: "{{instance_type}}"
      image: "{{image}}"
      count: "{{instance_count}}"
      wait: true
      wait_timeout: "{{wait_timeout}}"
      region: "{{region}}"
      instance_tags:
        Name: "{{ lookup('env', 'USER') }}-{{ key_name }}"
      volumes:
      - device_name: /dev/sdb
        volume_size: 20
        delete_on_termination: true
    register: ec2

  - name: Add new instances to host group
    add_host: hostname={{item.public_ip}} groupname=nodes
    with_items: ec2.instances

  - name: Add first instance to coordinators group
    add_host: hostname={{item.public_ip}} groupname=coordinators
    with_items: ec2.instances[:1]

  - name: Add first instance to rmnode group
    add_host: hostname={{item.public_ip}} groupname=rmnode
    with_items: ec2.instances[:1]

  - name: Add first instance to rmnode_private group
    add_host: hostname={{item.private_ip}} groupname=rmnode_private
    with_items: ec2.instances[:1]

  - name: Add first instance to ganglia_master group
    add_host: hostname={{item.private_ip}} groupname=ganglia_master
    with_items: ec2.instances[:1]

  - name: Add remaining instances to workers group
    add_host: hostname={{item.public_ip}} groupname=workers
    with_items: ec2.instances[1:]

  - name: Add all instances to nmnodes group
    add_host: hostname={{item.public_ip}} groupname=nmnodes
    with_items: ec2.instances

  - name: Add all instances to nmnodes_private group
    add_host: hostname={{item.private_ip}} groupname=nmnodes_private
    with_items: ec2.instances

  - add_host: hostname={{item.dns_name}} groupname=coordinator_name
    with_items: ec2.instances[:1]

  - add_host: hostname={{item.dns_name}} groupname=worker_names
    with_items: ec2.instances[1:]

  - name: Wait for SSH to come up
    local_action: wait_for host={{ item.public_dns_name }} port=22 delay=60 timeout=320 state=started
    with_items: ec2.instances

  # - name: Create a volume and attach
  #   ec2_vol:
  #     volume_size: 20
  #     instance: "{{item.id}}"
  #     region: "{{region}}"
  #   with_items: ec2.instances
  #   register: ec2_volumes

  # - name: Add tags to volumes
  #   ec2_tag:
  #     resource: "{{item.volume_id}}"
  #     region: "{{region}}"
  #     state: present
  #     tags:
  #       Name: "{{ lookup('env', 'USER') }}-{{ key_name }}"
  #   with_items: ec2_volumes.results

  - name: Create new ssh key-pair#generate a keylocally - this  will generate an error(ignored) if key exists... 
    shell: ssh-keygen -q -t rsa -N "" 
               -f {{ new_priv_key }}
    delegate_to: localhost
    ignore_errors: yes

- name: Set up SSH private key on coordinator
  hosts: coordinators
  remote_user: ubuntu
  sudo: no
  tasks:
  - copy: src={{ new_priv_key }} dest={{ remote_new_priv_key }} owner=ubuntu mode=400

- name: Set up SSH public key on workers
  hosts: workers
  remote_user: ubuntu
  sudo: no
  tasks:
  - authorized_key: user=ubuntu key="{{ item }}"
    with_file:
    - "{{ new_pub_key }}"

# - name: Build hosts file on all nodes
#   hosts: nodes
#   remote_user: ubuntu
#   sudo: yes
#   tasks:
#     - name: Build hosts file (backups will be made)
#       lineinfile: dest=/etc/hosts regexp='{{ hostvars[item].ansible_hostname }}$' line='{{ hostvars[item].private_ip }} {{ item }} {{ hostvars[item].ansible_hostname }}' state=present backup=yes
#       when: hostvars[item].ansible_default_ipv4.address is defined
#       with_items: groups['all']

- name: Configure common functionality on all nodes
  hosts: nodes    
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - basenode
    - yarn-common
    - postgres
    # - ganglia-client

- name: Configure YARN RM
  hosts: rmnode
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - yarn-rm

- name: Configure YARN NM
  hosts: nmnodes
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - yarn-nm
    
- name: Configure and launch Myria on coordinator
  hosts: coordinators
  remote_user: ubuntu
  sudo: yes
  gather_facts: false
  roles:
    - myria-python
    # - ganglia
    - myria

- name: list the name of master
  hosts: coordinators
  gather_facts: false
  remote_user: ubuntu
  sudo: yes  
  tasks:
    debug: msg= "myria coordinator and ganglia master IP is- {{play_hosts}}, user for ssh - ubuntu"
